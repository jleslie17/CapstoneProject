---
title: "Building a tool to assess business performance based on customer reviews"
author: "Jonathan Leslie"
date: "November 22, 2015"
output: 
  pdf_document: 
    fig_caption: yes
---

#Introduction
With the increasing popularity of on-line crowd-sourced review databases such as Yelp, both consumers and business owners have access to a wealth of customer review data that was not possible a decade ago. For the business owner, this data represents a valuable resource, providing insight into customer satisfaction and business performance. While objective assessments such as star ratings and tick-boxes may give some idea as to customer satisfaction, they do little to provide real insight into exactly how a given business is meeting the expectations of its customers, or as the case may be, falling short. 

To fill this gap, customers are encouraged to write reviews that appear as blocks of text. These give the consumer a chance to elaborate on his or her experience with more specific descriptions and they offer a wealth of information for the business owner. Unfortunately, reading customer reviews can be a long, painstaking process. For the business owner wanting to draw general conclusions from hundreds of such documents, the task can be arduous and prohibitively time-consuming. 

This project is a feasibility study aimed at creating an application that can help streamline this process, making it easier for business owners to gain more insight into the satisfaction of their customers from Yelp reviews. By submitting a query by Yelp business ID, the application will return several pieces of information. The first is a plot of average star ratings (averaged monthly) over time, showing the general trend in the business’ customer satisfaction. The second is list of words that are associated with the business’ positive and negative reviews, using text mining algorithms and a user-defined threshold star rating (to distinguish “positive” from “negative” reviews). If, for example, a restaurant owner discovers that the word “wait” is often found in the negative reviews, he or she might infer that customers are often critical of how long they must wait for either seating or food/drink service. The goal of this project is to determine if such text-mining algorithms can be tuned to provide useful information to the business owner.

#Methods and Data
##Sourcecode
The R code used for this study can be found in this report's Github repository: https://github.com/jleslie17/CapstoneProject
##Loading Data
The data for this study came from the Yelp Dataset Challenge (http://www.yelp.com/dataset_challenge). This dataset includes five JSON files corresponding to several aspect of Yelp review data and should be unzipped in the working directory. For this study, I used only the files pertaining to business IDs and reviews. I loaded the files of interest as below and saved them as rds files for subsequent analyses.
```{r, message=F, echo=F}
library(jsonlite)
library(readr)
library(tm)
library(dplyr)
library(zoo)
library(ggplot2)
require(wordcloud)
library(tikzDevice)
```
```{r, eval=FALSE, echo=F}
PATH <- "yelp_dataset_challenge_academic_dataset"
BusData <- stream_in(file(paste(PATH, "/",
                                "yelp_academic_dataset_business.json",sep = "")))
reviewData <- stream_in(file(paste(PATH, "/", 
                                   "yelp_academic_dataset_review.json", sep = "")))
saveRDS(reviewData, "reviewData.rds")
saveRDS(BusData, "businessData.rds")
```

##Subsetting the data into a shortlist
Becuase this is a feasibility study, I used only a subset of the data. This application could easily be expanded to include all businesses in the data set. It should be noted, however, that with fewer reviews, data describing customer satisfaction (see section below) may become noisy. For this reason, I restricted my feasibility study to a shortlist of businesses consisting of only restaurants and only those restaurants that had 100 or more reviews in the Yelp data set. 

```{r, echo=FALSE}
#Reload the data
BusData <- readRDS("businessData.rds")
ReviewData <- readRDS("reviewData.rds")

#Grab all businesses that have "Restaurants" in their category
Restaurants <- BusData[grepl("Restaurants", BusData$categories),]
#Grabbing all reviews of the restaurant businesses
RestRevs <- ReviewData[ReviewData$business_id %in% 
                               Restaurants$business_id,]
#Selecting a shortlist of restaurants that have 50 or more reviews
Threshold <- 100
RestsHiCount <- Restaurants[Restaurants$review_count >= Threshold,]
#Gather all the reviews for those restaurants
RestRevsHiCount <- RestRevs[RestRevs$business_id %in%
                                    RestsHiCount$business_id,]
```

##Examining changes in performance over time
To examine the change in customer satisfaction over time, I wrote a script that gathered review data for a given business (using the business_id field of the business data file, assigned to the variable BID (Business ID). This used only the business_id, review_id, date, stars and text variables of the review data file. Reviews were gathered by month using the as.yearmon() command and average monthly star ratings were calculated. The first six lines of an example data frame are shown below.

```{r, echo=F}
#Will have BID defined here.
BID <- "2WHP5nhS1rFszfRBKe6fWQ" 

#This is where I put in the business ID of interest
#Here we build a dataframe with the monthly averages
#for stars from the BID
BIDRevs <- RestRevsHiCount[RestRevsHiCount$business_id == BID,]
#Make a new data frame with only stars and date data
BIDStarsDates <- select(BIDRevs, business_id, 
                      date, stars, review_id, text)
#Add a variable 'YearMonth' that is only the month, ignoring days
BIDStarsDates$YearMonth <- strftime(BIDStarsDates$date, "%Y-%m")
BIDStarsDates$YearMonth <- as.Date(as.yearmon(BIDStarsDates$YearMonth))
#Group by business and YearMonth
BIDStarsDatesGrouped <- group_by(BIDStarsDates, business_id, YearMonth)
#Calculate the average stars per month and discard RevID, Date, Text
BIDStarsDatesGrouped <- summarise(BIDStarsDatesGrouped, 
                                 AvStarsPerMonth = mean(stars))
#Convert back into a data frame
BIDStarsDatesGrouped <- data.frame(BIDStarsDatesGrouped)
head(BIDStarsDatesGrouped)
```

##Examining review texts
To perform text-mining, I used the tm package. The program generated a corpus for all reviews in each pool (good and bad). The corpora were preprocessed to remove whitespace, transform all words to lowercase, remove stopwords (such as 'the') and stemmed to retrieve word radicals (free of suffixes). Punctuation was also removed. Document-term matrices were generated for each corpus, and mean frequency (how often each term appeared in a corpus) was calculated for each term. The terms were then sorted in order of decreasing frequency and the top 20 were printed as output.


#Results
##Sample business
For the remainder of this report, I have shown the data for a single example restaurant with the Yelp business id `r BID`. Because this application is meant to function as a tool for the business owner to investigate performance, I reasoned that in this context, an analysis of an individual business would be more useful than a general analysis of customer tastes. The following sections describe the steps in performing the analysis for this sample business.

##Examining changes in performance over time
A central tenant of business is to “know your audience”. While a business may have met the demands of its audience well in the past, consumer taste changes quickly, and it can be hard to stay on top of that as a business owner. To assess how well a business is meeting the demands of its public, I wanted to examine ratings over time. 

To visualise this trend, the program plots average stars over time and draws a linear regression line. The slope of this line can be thought of as the trend in customer satisfaction.

```{r, echo=F}
fit <- lm(AvStarsPerMonth~YearMonth, data = BIDStarsDatesGrouped)
```
```{r, echo=F, out.width='.49\\textwidth', fig.align='center'}
#Plot the averages over time
Data <- BIDStarsDatesGrouped
g <- ggplot(Data, 
             aes(x = YearMonth, y = AvStarsPerMonth))
p <- g + geom_point() + 
        stat_smooth(method = lm, colour = "blue") +
        ggtitle("Plot 1 \nChanges in star ratings over time") +
        ylim(0,5) +
        xlab("Year") +
        ylab("Average Star rating \n(calculated monthly") +
        theme(axis.title.x=element_text(size = 14)) +
        theme(axis.title.y=element_text(size = 14)) +
        ggplot2::annotate("text",
                          x=as.Date("2014-07-01"), y=2.2,
                          label="slope = -0.48 stars/year (±95% CI)", 
                          colour = "blue")
print(p)
```

In this example, the change in star rating (stars per year) for business `r BID` is:  __`r round(365*fit$coef[[2]], 2)`__

As we can see from the plot, the reviews have, on average, gotten worse with time. The owner of this restaurant might want to know why. The next section deals with ways to help answer that question.

##Generating word lists for good and bad reviews
To help shed light on factors that might be contributing to customer satisfaction (either for the good or the bad), I wanted to emply text-mining techniques on the texts that accompany each review. I hypothesize that such an analysis might reveal trends associated with poor customer satisfaction.

Since each business owner may want to decide what star rating differentiates between a "good" and a "bad" review, I allow this threshold to be set. In this case, it is set with the StarsThresh variable. In this example, StarsThresh is set to 3.5, so reviews receiving 1, 2 or 3 stars will be pooled in the "bad" group, and the rest will be considered "good". 

```{r}
StarsThresh <- 3.5
```

The text mining algorithm generates a so-called corpus for each group, with the text from each review within the groups functioning as a disctinct document. The algorithm goes on to apply preprocessing techniques as described under the Methods and Data section above to yeild final corpora to be used for subsequent analyses. 

The good and bad corpora were used to generate document-term matrices, which were further used to produce final lists of frequently used terms. The 20 most commonly-used terms (minus stopwords such as "the" and "an") for each group are listed below:

```{r, echo=FALSE, comment=''}
QueryDB <- BIDStarsDates
QueryDBGood <- QueryDB[QueryDB$stars > StarsThresh,]
QueryDBBad <- QueryDB[QueryDB$stars <= StarsThresh,]

#Function to make a corpus
GetCorpus <- function(inputDB){
        CorpusTemp <- VCorpus(VectorSource((inputDB$text)))
        CorpusTemp <- tm_map(CorpusTemp, stripWhitespace)
        CorpusTemp <- tm_map(CorpusTemp, content_transformer(tolower))
        CorpusTemp <- tm_map(CorpusTemp, removeWords, stopwords("english"))
        CorpusTemp <- tm_map(CorpusTemp, stemDocument) 
        CorpusTemp <- tm_map(CorpusTemp, removePunctuation)
        return(CorpusTemp)
}

CorpusBad <- GetCorpus(QueryDBBad)
CorpusGood <- GetCorpus(QueryDBGood)

##Function to build DTM
getDTM <- function(inputCorp){
        dtmTemp <- DocumentTermMatrix(inputCorp)
        dtmTemp <- removeSparseTerms(dtmTemp,0.9)
        return(dtmTemp)
}

DTMGood <- getDTM(CorpusGood)
DTMBad <- getDTM(CorpusBad)
KeywordsGood <- sort(round(apply(DTMGood, MARGIN = 2, FUN = mean),2),
                     decreasing = T)
KeywordsBad <- sort(round(apply(DTMBad, MARGIN = 2, FUN = mean),2),
                    decreasing = T)
print("Keywords associated with good reviews:")
print(KeywordsGood[1:20])
print("Keywords associated with bad reviews:")
print(KeywordsBad[1:20])
```

##Word usage visualization
To better visualize word usage, I took advantage of the wordcloud package to produce a wordcloud for each group (good and bad reviews). This process included converting each document-term matrix into a data frame and employing the wordcloud() function as shown below.

```{r, dev='pdf', fig.show='hold', fig.cap='wordclouds'}
mGood <- as.matrix(DTMGood)
mBad <- as.matrix(DTMBad)

vGood <- sort(colSums(mGood), decreasing = T)
vBad <- sort(colSums(mBad), decreasing = T)
dGood <- data.frame(word = names(vGood), freq=vGood)
dBad <- data.frame(word = names(vBad), freq=vBad)

wordcloud(dGood$word, dGood$freq, scale=c(2.5,0.5), 
          max.words=50, random.order=FALSE, 
          rot.per=0.35, use.r.layout=FALSE, 
          colors=brewer.pal(8, 'Dark2'))
wordcloud(dBad$word, dBad$freq, scale=c(2.5,0.5), 
          max.words=50, random.order=FALSE, 
          rot.per=0.35, use.r.layout=FALSE, 
          colors=brewer.pal(8, 'Dark2'))
```

Word clouds for "good" reviews (left) and "bad" reviews (right).

These word clouds help to give a better visual appreciation for what topics have often been discussed in customer reviews, and may provide useful information to the business owner. 

#Discussion
The goal of this project was to explore ways in which business owners might be able to make better use of customer review data. Specifically, I was interested in (1) assessing changes in customer satisfaction over time and (2) using text-mining approaches to extract useful information from customer reviews. This report is a feasibility study, aimed at determining if my program achieves these goals. 

In the first case, I believe the algorithm was largely successful. Using linear regression in concert with appropriate grouping and averaging parameters, this program produces a clear picture of trends in average customer satisfaction over time. The robustness of this analysis is dependent on several factors, including the number of reviews gathered, the variation in stars awarded and the period over which reviews are averaged. I restricted this study to only those businesses that had more than 100 reviews, hoping that this would make the algorithm less susceptible to these confounding factors. For businesses having fewer reviews, the period over which star ratings were averaged would probably have to be adjusted in order to smooth out noise. Nonetheless, for this example business (and many others not shown), the algorithm produces a nice visualization of temporal trends in customer satisfaction.

For the second part of the analysis I employed text-mining techniques to extract meaningful keywords from review texts. When analyzing word clouds one must use caution. For instance, in this example, many words are shared between good reviews and bad ones. Words such as "food", "place" and "good" show up in both groups with similar frequencies and therefore don't tell use much about customer satisfaction. Other words are more telling. For example, in the positive reviews, we see that the words "lobster", "fresh", and "seafood" appear with a high frequency. In contrast, the words "order", "servic" and "menu" show strongly in the negative reviews. One might infer, then, that when customers of this business are happy with their experience, the quality of the food is something they notice. When they are unhappy, however, the service seems to be where the business is falling short. 


In the case of this example, the program worked reasonably well. Text mining is a complicated endeavour, and it is rare that the output gives a black-and-white picture of the trends in term usage. I suspect that this algorithm could be tuned to be more robust, and in a final application, it may be wise to make these tuning parameters variable that can be adjusted by the user. Ultimately, whether or not such text-mining applications are useful to the business owner may largely depend on the individual. 


